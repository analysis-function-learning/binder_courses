{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1><font size=7> Case Study C</font> </h1> </center>\n",
    "\n",
    "# Predicting AirBnB Prices - Example Solution - part 1\n",
    "\n",
    "This notebook contains the data wrangling example answer to Case Study C. There are a wide range of approaches to this task, you may decide to go down a different route than taken here.\n",
    "\n",
    "In this notebook, data will be cleaned. We will be reading in the data, imputing missing values. Encoding certain values and joining required data. The output of this notebook will be a csv file, which machine learning will be conducted upon in a different notebook. Note: The datasets to be used in this notebook will be airbnb listings for manchester and bristol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce # used to join multiple data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manchester_df= pd.read_csv(\"..//..//data//airbnb//listings//manchester_listings.csv\")\n",
    "greater_manchester_df= pd.read_csv(\"..//..//data//airbnb//listings//greater_manchester_listings.csv\")\n",
    "bristol_df= pd.read_csv(\"..//..//data//airbnb//listings//bristol_listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just so I can identity the cities later I will create a new column called city\n",
    "manchester_df['city'] = 'Manchester'\n",
    "\n",
    "bristol_df['city'] = 'Bristol'\n",
    "\n",
    "greater_manchester_df['city'] = 'Manchester'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Check to see which columns are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_differences_bm = manchester_df.columns.difference(bristol_df.columns)\n",
    "column_differences_bm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All good, we wont be using most of those columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Imputing Data 1 (There will be a 2 later when I bfill the bedrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greater manhester and bristol missing bathroom data but has bathroom text so will take first vlaue\n",
    "greater_manchester_df['bathrooms'] = greater_manchester_df['bathrooms_text'].str[0:1]\n",
    "bristol_df['bathrooms'] = bristol_df['bathrooms_text'].str[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Selecting the columns we want and concatting bristol and manchester dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id', 'neighbourhood_cleansed', 'city', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates',\n",
    "           'bathrooms', 'bedrooms', 'price', 'minimum_nights', 'maximum_nights',\n",
    "           'availability_365', 'number_of_reviews', 'reviews_per_month',\n",
    "           'host_is_superhost', 'amenities']\n",
    "\n",
    "\n",
    "manchester_df = manchester_df[columns]\n",
    "greater_manchester_df = greater_manchester_df[columns]\n",
    "bristol_df = bristol_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([manchester_df, bristol_df, greater_manchester_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can we see there is a dollar sign in front of the price, which we need to get rid of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the dollar sign before price\n",
    "combined_df['price'] = combined_df.price.str.replace(\"\\$|,\", '').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Imputing data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore missing data\n",
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to fill in bedrooms , bathrooms 1, and reviews to 0. Rationale: Who would hire an airbnb without atleast a bed, or a bathroom. Reviews are NaNs anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['bathrooms'].fillna(value=1, inplace=True)  # 1 bathroom\n",
    "combined_df['reviews_per_month'].fillna(value=0, inplace=True)  # reviews put to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now only bedrooms to do. I am going to order my accomodate and use bfill so ones with similar accomodation levels will have similar levels of bedrooms logically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by accomodates\n",
    "combined_df = combined_df.sort_values(by='accommodates', ascending=False)  \n",
    "\n",
    "# now fill the empty bedrooms using bfill\n",
    "combined_df['bedrooms'].fillna(axis=0, method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No more empty values!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Manually encode amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data has a list of amenities. However, they're in list in a column so will need to manually One hot Encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.amenities.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = [\"wifi\", \"kitchen\", \"parking\", \"tv\", \"wash\", \"washer\", \"garden\", \"balcony\"]\n",
    "\n",
    "# make zero columns for selected amenities, to be one hot encoded manually\n",
    "for amenity in amenities:\n",
    "    combined_df[\"has_\" + amenity] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loc and Regex to manually OHE\n",
    "# Check list of amenities to see if desired is mentioned\n",
    "\n",
    "for amenity in amenities:\n",
    "    contains_mask = combined_df['amenities'].str.lower().str.contains(amenity)\n",
    "    combined_df.loc[contains_mask, \"has_\" + amenity] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Combining Supplementary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use a lookup table that links longitude and latitudes to [lower layer super output areas (LSOA)'s](https://www.ons.gov.uk/methodology/geography/ukgeographies/censusgeography). This will allow us to join the location of each property to other data.\n",
    "\n",
    "This look up table was created using a spatial join, seeing which points (properties) exist within the polygons (LSOAs). However, as geospatial work is not part of this course, the resulting table has been given instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Loading LSOA lat/long lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the data LSOA lookup table\n",
    "lsoa = pd.read_csv(\"../../data/airbnb/lsoa/lat_lon_lsoa_join.csv\", usecols=[1,2,3])\n",
    "lsoa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Merging index of multiple deprvation (IMD) data and median house price data to shape data (including minor wrangling). Can be found at lsoa level online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read imd and median house price data\n",
    "imd = pd.read_csv(\"..//..//data//airbnb//imd//imd.csv\")\n",
    "median_house_price = pd.read_csv(\"..//..//data//airbnb//house_prices//median_house_lsoa_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns in place\n",
    "imd.rename(columns=({\"LSOA code (2011)\":\"LSOA11CD\"}), inplace=True)\n",
    "median_house_price.rename(columns=({\"LSOA code\":\"LSOA11CD\",\n",
    "                                    \"Year ending Jun 2020\": \"median_house_price_2020\"}), \n",
    "                          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no idea why median house price has 2 empty columns, but I'm going to drop them\n",
    "median_house_price.drop(columns=[\"Unnamed: 5\",'Unnamed: 6'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annoyingly empty values have a :, so one extra step before dropping empty values\n",
    "median_house_price['median_house_price_2020'] = (median_house_price['median_house_price_2020']\n",
    "                                                 .str.replace(':', 'NaN'))\n",
    "median_house_price = median_house_price.dropna()  # dropnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the comma from price\n",
    "median_house_price['median_house_price_2020'] = (median_house_price['median_house_price_2020']\n",
    "                                                 .str.replace(',', '')\n",
    "                                                 .astype(float))\n",
    "# Remove remaining missing values\n",
    "median_house_price = median_house_price.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge imd and house prices\n",
    "imd_median_house = imd.merge(median_house_price, on=\"LSOA11CD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd_median_house = imd_median_house[['LSOA11CD', 'Index of Multiple Deprivation (IMD) Score',\n",
    "                                     'median_house_price_2020']]  # subset required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd_median_geography = lsoa.merge(imd_median_house, on='LSOA11CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd_median_geography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.Journey time Data (From department from transport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "journey_town = pd.read_csv(\n",
    "    \"..//..//data//airbnb//journey_data//min_town_centre_ptw.csv\")\n",
    "journey_station = pd.read_csv(\n",
    "    \"..//..//data//airbnb//journey_data//avg_time_rail_station_ptw.csv\")\n",
    "journey_airport = pd.read_csv(\n",
    "    \"..//..//data//airbnb//journey_data//avg_time_airport_ptw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset columns and change column name for ease of use\n",
    "\n",
    "# town\n",
    "journey_town = journey_town.rename(columns=(\n",
    "    {'mins_nearest_town_pubt_walk': 'minutes_to_town', 'LSOA_code': 'LSOA Code'}))\n",
    "journey_town = journey_town[['LSOA Code', 'minutes_to_town']]\n",
    "# station\n",
    "journey_station = journey_station.rename(\n",
    "    columns=({'Average travel time to rail station(minutes)': 'minutes_to_rail'}))\n",
    "journey_station = journey_station[['LSOA Code', 'minutes_to_rail']]\n",
    "# airport\n",
    "journey_airport = journey_airport.rename(\n",
    "    columns=({'Average minimum journey time (minutes)': 'minutes_to_airport'}))\n",
    "journey_airport = journey_airport[['LSOA Code', 'minutes_to_airport']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the journey data together into one frame\n",
    "journey_dfs = [journey_town, journey_station, journey_airport]\n",
    "\n",
    "df_all_journeys = reduce(lambda left, right: pd.merge(\n",
    "    left, right, on='LSOA Code'), journey_dfs)  # reduce them 2 one dataframe (basically a merge)\n",
    "df_all_journeys = df_all_journeys.rename(columns=({'LSOA Code': 'LSOA11CD'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_journeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. Merging all supplementary data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine transport times, imd and median house price\n",
    "supp_data=imd_median_geography.merge(df_all_journeys,on='LSOA11CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Join LSOA supplementary data with listings using lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_supp = combined_df.merge(supp_data, on=[\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_supp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Final wranglings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for nas\n",
    "airbnb_with_supp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_supp=airbnb_with_supp.drop(columns=['amenities','reviews_per_month']) #dont need these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_supp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Turn host is superhost to binary and clean out the lettters in the bathrooms (I dont know why they are there, but we just give them a 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_supp['bathrooms'].replace({'H': 1}, inplace=True)\n",
    "airbnb_with_supp['bathrooms'].replace({'S': 1}, inplace=True)\n",
    "airbnb_with_supp['bathrooms'].replace({'P': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_supp['bathrooms'] = airbnb_with_supp['bathrooms'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE the room type. Also convert t/f, to binary\n",
    "airbnb_with_supp = pd.get_dummies(airbnb_with_supp, columns=['room_type'])\n",
    "airbnb_with_supp = airbnb_with_supp.replace({'t': 1, 'f': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_supp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_supp #everything looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_with_supp.to_csv('../../data/airbnb/example_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
