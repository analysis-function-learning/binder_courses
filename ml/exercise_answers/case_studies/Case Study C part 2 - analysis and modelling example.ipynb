{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1><font size=7> Case Study C</font> </h1> </center>\n",
    "\n",
    "# Predicting AirBnB Prices - Example Solution - part 1\n",
    "\n",
    "This notebook will take the data that was cleaned in the Case Study C part 1 notebook.\n",
    "\n",
    "This notebook focuses on the analysis of features and regression modelling to predict the \"price\" of listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df=pd.read_csv('../../data/airbnb/example_cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Distribution of price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "airbnb_df['price'].plot.density()\n",
    "plt.plot(airbnb_df['price'], [0.0001]*len(airbnb_df), '|', color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above that there are some substantial outliers in our data (£8000 for a night? really?) which may impact our ability to model. The data is positive (prices we hope) and has a long right tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df['price'][airbnb_df['price'] < 500].plot.density();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the log of the data shows we have a near lognormal distribution\n",
    "airbnb_df['price'][airbnb_df['price'] < 500].apply(np.log1p).plot.density();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Impact of factors on price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Property type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.boxplot(column='price', by='property_type', figsize=(20,6), rot=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None): # this line stops our Series collapsing\n",
    "    print(airbnb_df.groupby(\"property_type\")[\"price\"].agg(np.mean).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would have also done room type, but that's been encoded so can't plot it in a boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.plot.scatter(x='number_of_reviews', y='price', alpha=0.4, figsize=(20,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df[airbnb_df[\"price\"] < 500].plot.scatter(x='number_of_reviews', y='price', alpha=0.3, figsize=(20,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the price outliers there isn't a clear relationship. There is not a clear linear relationship, a transformation of the data could better show a relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.scatter(np.log1p(airbnb_df['number_of_reviews']), airbnb_df['price'], alpha=0.3)\n",
    "plt.title('Price vs log(reviews)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentially some positive correlation, however, this is unclear from plotting alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Bathrooms, bedrooms and accomodates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax=plt.subplots(figsize=(4,4))\n",
    "\n",
    "plt.scatter(x=airbnb_df['bathrooms'], y=airbnb_df['price'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some outliers with high price or high bathroom number, but in this visualisation difficult to see a clear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax=plt.subplots(figsize=(4,4))\n",
    "airbnb_df_subset = airbnb_df[airbnb_df['price'] < 500]\n",
    "plt.scatter(x=airbnb_df_subset['bathrooms'], y=airbnb_df_subset['price'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be *some* correlation, or at least a relationship. The outlier high bathrooms do tend to cost more. The properties with no bathrooms cost less in general, there is some trend between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax=plt.subplots(figsize=(4,4))\n",
    "\n",
    "plt.scatter(x=airbnb_df['bedrooms'], y=airbnb_df['price']);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax=plt.subplots(figsize=(4,4))\n",
    "\n",
    "plt.scatter(x=airbnb_df['accommodates'], y=airbnb_df['price']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature engineering\n",
    "\n",
    "Out non-numeric columns need to be converted into numerical formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df = airbnb_df.copy()\n",
    "\n",
    "# take the log of reviews as new feature\n",
    "engineered_df['logreviews'] = np.log1p(engineered_df['number_of_reviews'])  \n",
    "\n",
    "\n",
    "engineered_df = pd.get_dummies(engineered_df, columns=[\n",
    "                               'city'])  # OHE the cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Inital Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and target\n",
    "# remove unique features and unneeded features\n",
    "\n",
    "features = engineered_df.drop(columns=['id', 'property_type', 'LSOA11CD', 'price', \n",
    "                                       'number_of_reviews', 'neighbourhood_cleansed'])\n",
    "target = engineered_df['price']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train / test split\n",
    "# the earlier we do this, the better with regards to\n",
    "# influencing our decisions using the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "# fit scaler to training data\n",
    "# robust scaling all numeric features, we have some data with significant outliers\n",
    "# we do not want impacting our scales\n",
    "X_train_scaled = scaler.fit_transform(X=X_train)\n",
    "\n",
    "# transform but do NOT fit on the test data\n",
    "X_test_scaled = scaler.transform(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters to be searched in the cross validated linear models\n",
    "\n",
    "alphas = [1000, 100, 50, 20, 10, 1, 0.1, 0.01]\n",
    "\n",
    "lr = LinearRegression()\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "lasso = LassoCV(alphas=alphas, max_iter=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are choosing to evaluate using mean average error because it is versatile to outliers in the target distribution. Prices that are way off the average (such as £8,000) will not impact the evaluation as significantly.\n",
    "\n",
    "This choice is made due to the challenge of predicting these outliers. In addition, just because a listing is made and the price is set, this does not mean:\n",
    "\n",
    "* any one has actually ever paid that amount\n",
    "* it is a reflection of value based on the attributes in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each model type\n",
    "for model, name in zip([lr, ridge, lasso], ['LinearRegression', 'RidgeRegression', 'LassoRegression']):\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # generate prediction to evaluate on training set\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    mae_train = mean_absolute_error(y_pred=y_pred_train, y_true=y_train).round(3)\n",
    "    \n",
    "    # generate predictions on the TEST set\n",
    "    # we do both to compare\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    mae_test = mean_absolute_error(y_pred=y_pred_test, y_true=y_test).round(3)\n",
    "    \n",
    "    best_alpha = ''\n",
    "    if name != 'LinearRegression':\n",
    "        best_alpha = ' best alpha: ' + str(model.alpha_)\n",
    "        \n",
    "    print(f\"{name}\\n\\t MAE train: {mae_train}\\t  MAE test:{mae_test} \\t{best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn regressor\n",
    "grid_params = {\n",
    "    'n_neighbors': [3, 7, 12, 14, 40, 60, 80, 100],\n",
    "    'weights': ['distance', 'uniform'],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsRegressor(), grid_params,\n",
    "                    cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best estimator: ', grid_result.best_estimator_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = grid_result.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "print(\"Best KNN rmse:\", mean_absolute_error(y_pred=y_pred_knn, y_true=y_test).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN outperforms the linear / regularized models. This shows there may be significant non-linearity in the relationships.\n",
    "\n",
    "We can further improve our model by transforming more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring target transformation\n",
    "\n",
    "Our target is highly skewed. If we transform it into a different distribution, train the model, then transform it back to the original dimension to evaluate it we can improve our model's performance. This is because our model will find it easier to relate features to a normal target rather than a skewed target.\n",
    "\n",
    "We are going to assume out `\"price\"` column follows a log-normal distribution. Therefore, to convert it to a normal distribution we will take the log of it (in practice, a log(X+1) transformation to avoid undefined values). To convert back to the regular distribution we will need to take the exponent of each value (the opposite of log) and then subract 1.\n",
    "\n",
    "*forward transformation for each data point:* $log(x+1)$\n",
    "\n",
    "*backward transformation for each data point:* $exp(x) - 1$\n",
    "\n",
    "This will *hopefully* improve our model's ability to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log, y_test_log = np.log1p(y_train), np.log1p(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each model type\n",
    "for model, name in zip([lr, ridge, lasso], ['LinearRegression', 'RidgeRegression', 'LassoRegression']):\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(X_train_scaled, y_train_log)\n",
    "    \n",
    "    # generate prediction to evaluate on training set\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    mae_train = mean_absolute_error(y_pred=np.expm1(y_pred_train), y_true=y_train).round(3)\n",
    "    \n",
    "    # remember np.exp(y_train_log) == y_train\n",
    "    \n",
    "    # generate predictions on the TEST set\n",
    "    # we do both to compare\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    mae_test = mean_absolute_error(y_pred=np.expm1(y_pred_test), y_true=np.expm1(y_test_log)).round(3)\n",
    "    \n",
    "    best_alpha = ''\n",
    "    if name != 'LinearRegression':\n",
    "        best_alpha = ' best alpha: ' + str(model.alpha_)\n",
    "    print(f\"{name}\\n\\t MAE train: {mae_train}\\t  MAE test:{mae_test} \\t{best_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that from the above our performance has already improved, reducing the MAE from ~38 to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn regressor\n",
    "grid_params = {\n",
    "    'n_neighbors': [3, 7, 12, 14, 40, 60, 80, 100],\n",
    "    'weights': ['distance', 'uniform'],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsRegressor(), grid_params,\n",
    "                    cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train_scaled, y_train_log)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best estimator: ', grid_result.best_estimator_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = grid_result.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "print(\"Best KNN rmse:\", mean_absolute_error(y_pred=np.expm1(y_pred_knn), y_true=y_test).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have yet again shaved off more error in our model, this time jumping from 32 to 26 by just transforming our target with a log and back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Improved modelling (Playing around with sampling and data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will only keep airbnbs that have more than 5 reviews, clip high prices to 3 standard deviations and take an even sample of manchester and bristol.\n",
    "\n",
    "It's important we only do this with our **training** data. We don't want to bias the evaluation step. If we were to remove data from our **test** set we would be making the evaluation easier,  decreasing the representativeness of the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_engineered_df = airbnb_df.copy()\n",
    "\n",
    "# take the log of reviews as new feature\n",
    "new_engineered_df['logreviews'] = np.log1p(new_engineered_df['number_of_reviews'])  \n",
    "\n",
    "\n",
    "new_engineered_df = pd.get_dummies(new_engineered_df, columns=[\n",
    "                               'city']) \n",
    "\n",
    "new_features = new_engineered_df.drop(columns=['id', 'property_type', 'LSOA11CD', \n",
    "                                       'number_of_reviews', 'price', 'neighbourhood_cleansed'])\n",
    "new_target = new_engineered_df['price']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new split with new features\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(features, \n",
    "                                                                    target, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask so it can be applied to both X_train and y_train\n",
    "# we only have the number of reviews as a log feature, but it's easy to convert to\n",
    "review_number_mask = X_train_new[\"logreviews\"] > np.log1p(5)\n",
    "\n",
    "X_train_new, y_train_new = X_train_new[review_number_mask], y_train_new[review_number_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what price is needed to cut off for lower and upper price\n",
    "\n",
    "# get the mean and 1 standard deviation\n",
    "mean_price, std_price = y_train_new.mean(), y_train_new.std()\n",
    "\n",
    "# identify outliers defined as 3 std out from mean\n",
    "cut_off = std_price * 3\n",
    "lower_bound, upper_bound = mean_price - std_price, mean_price + std_price\n",
    "\n",
    "print(\"mean\", mean_price)\n",
    "print(\"std\", std_price)\n",
    "print(\"lower bound\", lower_bound)\n",
    "print(\"upper bound\", upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably not many prices below that lower bound... As we are assuming a normal distribution (by using mean and variance) we could convert to a normal distribution using `np.log1p` again. Instead of the lower bound, lets choose a sensible boundry using *domain knowledge*. There probably are not reasonable to model properties going for less than £15 per night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_mask = (y_train_new > 15) & (y_train_new < upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, y_train_new = X_train_new[outlier_mask], y_train_new[outlier_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce an even sample across Bristol and Manchester for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new.groupby(\"city\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the data based on the city of origin\n",
    "X_train_new_reweighted = X_train_new.groupby(\"city\").sample(n=800, random_state=123).drop(columns=\"city\")\n",
    "\n",
    "X_test_new = X_test_new.drop(columns=\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only y that have the same index as the resulting X\n",
    "y_train_new_reweighted = y_train_new[X_train_reweighted.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_new_reweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_new_scaled = scaler.fit_transform(X=X_train_new_reweighted)\n",
    "\n",
    "# transform but do NOT fit on the test data\n",
    "X_test_new_scaled = scaler.transform(X=X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the previously initialized model objects - same search parameters\n",
    "\n",
    "# Loop through each model type\n",
    "for model, name in zip([lr, ridge, lasso], ['LinearRegression', 'RidgeRegression', 'LassoRegression']):\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(X_train_new_reweighted, y_train_new_reweighted)\n",
    "    \n",
    "    # generate prediction to evaluate on training set\n",
    "    y_pred_train = model.predict(X_train_new_reweighted)\n",
    "    mae_train = mean_absolute_error(y_pred=y_pred_train, y_true=y_train_new_reweighted).round(3)\n",
    "    \n",
    "    # generate predictions on the TEST set\n",
    "    # we do both to compare\n",
    "    y_pred_test = model.predict(X_test_new_scaled)\n",
    "    mae_test = mean_absolute_error(y_pred=y_pred_test, y_true=y_test_new).round(3)\n",
    "    \n",
    "    best_alpha = ''\n",
    "    if name != 'LinearRegression':\n",
    "        best_alpha = ' best alpha: ' + str(model.alpha_)\n",
    "        \n",
    "    print(f\"{name}\\n\\t MAE train: {mae_train}\\t  MAE test:{mae_test} \\t{best_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this has done has improved our prediction ability within the training set, but made our model much worse on the test set. This is because our test set contains data that our model simply hasn't seen anything like before. The test data may have \"price\" outside of the range set, and the learned parameters may be wrong for lower review counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1. Model diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting true vs predicted for the knn log model\n",
    "\n",
    "limit = 500\n",
    "\n",
    "# we need to have an equal scale to best interpret this graph\n",
    "# so the figure size must be the same for x and y\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot([0,limit],[0,limit], \"--\", c=\"r\") # plot straight line for comparison\n",
    "plt.scatter( y_test, np.expm1(y_pred_knn),alpha=0.2)\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.xlabel(\"True values\")\n",
    "plt.xlim(0, limit) # this excludes some outliers\n",
    "plt.ylim(0, limit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can see that the predictions are not consistently under or over predicting for the non-outlier data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting residuals / error\n",
    "residuals = y_test-np.expm1(y_pred_knn)\n",
    "plt.scatter(np.expm1(y_pred_knn),residuals, alpha=0.1)\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.xlabel(\"Predicted values\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots we can understand a few things:\n",
    "\n",
    "Our best model - \n",
    "* Under predicts high values of the prices / is unable to predict well the large price values\n",
    "* There doesn't appear to be a clear correlation between size of residuals and preducted value for the outliers\n",
    "\n",
    "When we consider how the knn regression works, taking the average of surrounding data points, we are unlikely to be able to predict these outliers, as we will always tend towards the mean.\n",
    "\n",
    "To further improve the model however, we could rebalance more classes for training and transform more features into different distributions that may be easier for our model to calculate relevant distances for.\n",
    "\n",
    "Our training and test splits appear to be similar in result, indicating that we have not yet overfit to the data (which is an interesting concept in of itself when thinking about the knn regressor), not have we underfit when using our tuned hyper parameters.\n",
    "\n",
    "Further exploration would entail looking at how to predict these higher values better, potentially with multi-level models or better outlier handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
